{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The objective of this notebook is to simulate a baseline case for the custom error metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the error metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ComputeErrorMetric(y_true,y_pred):\n",
    "    \n",
    "    df = pd.DataFrame({'y_true':y_true, 'y_pred':y_pred})\n",
    "    # home_wins\n",
    "    hw_fp = ((df.y_true != 1) & (df.y_pred == 1))\n",
    "    hw_tp = ((df.y_true == 1) & (df.y_pred == 1))\n",
    "    hw_fn = ((df.y_true == 1) & (df.y_pred != 1))\n",
    "    hw_tn = ((df.y_true != 1) & (df.y_pred != 1))\n",
    "    # away_win\n",
    "    aw_fp = ((df.y_true != -1) & (df.y_pred == -1))\n",
    "    aw_tp = ((df.y_true == -1) & (df.y_pred == -1))\n",
    "    aw_fn = ((df.y_true == -1) & (df.y_pred != -1))\n",
    "    aw_tn = ((df.y_true != -1) & (df.y_pred != -1))\n",
    "    #  draw\n",
    "    dd_fp = ((df.y_true != 0) & (df.y_pred == 0))\n",
    "    dd_tp = ((df.y_true == 0) & (df.y_pred == 0))\n",
    "    dd_fn = ((df.y_true == 0) & (df.y_pred != 0))\n",
    "    dd_tn = ((df.y_true != 0) & (df.y_pred != 0))\n",
    "\n",
    "    true_positive = sum(hw_tp + aw_tp + dd_tp)\n",
    "    false_positive = sum(hw_fp + aw_fp + dd_fp) \n",
    "    true_negative = sum(hw_tn + aw_tn + dd_tn)\n",
    "    false_negative = sum(hw_fn + aw_fn + dd_fn)\n",
    "\n",
    "    combined_error_metric = 11.0/13.0*false_positive/(false_positive+true_negative)+2.0/18.0*false_negative/(false_negative+true_positive)\n",
    "    \n",
    "    #precision = true_positive / (true_positive + false_positive)\n",
    "    #recall = true_positive / (true_positive + false_negative)\n",
    "    \n",
    "    return round(combined_error_metric,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set an artificial set of true and predicted values.\n",
    "\n",
    "The ratio of 1,0,-1 values are representative to the dataset. 10 home wins / 6 draws / 6 away wins\n",
    "\n",
    "The predicted value are repeating values of 1,0,-1 to simulate picking random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true = [1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,-1,-1,-1,-1,-1,-1]\n",
    "pred = [1,0,-1,1,0,-1,1,0,-1,1,0,-1,1,0,-1,1,0,-1,1,0,-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "cem = ComputeErrorMetric(true,pred)\n",
    "\n",
    "print round(cem,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the simulation is an error metric of 0.4. This can be used as a baseline value for 'random guessing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41\n"
     ]
    }
   ],
   "source": [
    "true = []\n",
    "pred = []\n",
    "for i in range(5000):\n",
    "    true.append(random.randint(-1,1))\n",
    "    pred.append(random.randint(-1,1))\n",
    "\n",
    "cem = ComputeErrorMetric(true,pred)\n",
    "\n",
    "print round(cem,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "0.41 is the error metric from randomly picking values between -1,1. This goes along with the experiment above that error metrics around 0.4 would be considered a random guess baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
