{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection Notebook\n",
    "\n",
    "This notebook will perform model selection on a Kernel SVM to predict binary classification\n",
    "\n",
    "- Home Win Result\n",
    "- Not Home Win Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.stats import sem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.stats import sem\n",
    "\n",
    "numFolds = 10\n",
    "\n",
    "date = '20170217'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed('01191988')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('/Users/mtetkosk/Google Drive/Data Science Projects/data/processed/%s_Matches_w_Features.csv'%(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "        print col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2280\n",
      "(2280, 196)\n"
     ]
    }
   ],
   "source": [
    "print len(data)\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "home_goals = data['home_team_goal']\n",
    "away_goals = data['away_team_goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del data['home_team_goal']\n",
    "del data['away_team_goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2280, 194)\n"
     ]
    }
   ],
   "source": [
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## First step is to set up training and holdout set\n",
    "def Assign_Train_Test(df):\n",
    "    num = random.randint(1,numFolds)\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Train_Test'] = data.apply(Assign_Train_Test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test length 246\n",
      "Train length 2034\n"
     ]
    }
   ],
   "source": [
    "## Chose holdout set as approx 10% of data\n",
    "holdout = data[data['Train_Test']==1]\n",
    "train = data[data['Train_Test']!= 1]\n",
    "\n",
    "# Remove the train_test variable from the dataframes\n",
    "del holdout['Train_Test']\n",
    "del train['Train_Test']\n",
    "\n",
    "print 'Test length ' + str(len(holdout))\n",
    "print 'Train length ' + str(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FitPredict(x_train,y_train,x_test,model):\n",
    "    \n",
    "    fit_model = model.fit(x_train,y_train)\n",
    "    preds = fit_model.predict(x_test)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "def ComputeErrorMetric(y_true,y_pred):\n",
    "    \n",
    "    #df = pd.DataFrame({'y_true':y_true, 'y_pred':y_pred})\n",
    "    # draw\n",
    "    #hw_fp = ((df.y_true != 1) & (df.y_pred == 1))\n",
    "    #hw_tp = ((df.y_true == 1) & (df.y_pred == 1))\n",
    "    #hw_fn = ((df.y_true == 1) & (df.y_pred != 1))\n",
    "    #hw_tn = ((df.y_true != 1) & (df.y_pred != 1))\n",
    "\n",
    "    #true_positive = sum(hw_tp)\n",
    "    #false_positive = sum(hw_fp)\n",
    "    #true_negative = sum(hw_tn)\n",
    "    #false_negative = sum(hw_fn)\n",
    "\n",
    "    #combined_error_metric = 10.0/13.0*false_positive/(false_positive+true_negative)+3.0/13.0*false_negative/(false_negative+true_positive)\n",
    "    \n",
    "    #precision = true_positive / (true_positive + false_positive)\n",
    "    #recall = true_positive / (true_positive + false_negative)\n",
    "    \n",
    "    f1score = f1_score(y_true,y_pred, average='binary')\n",
    "    precision = precision_score(y_true,y_pred, average='binary')\n",
    "    recall = recall_score(y_true,y_pred, average = 'binary')\n",
    "    \n",
    "    return round(f1score,2), round(precision,4), round(recall,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mtetkosk/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1     234\n",
       "10    214\n",
       "7     209\n",
       "3     209\n",
       "2     206\n",
       "8     201\n",
       "6     200\n",
       "5     200\n",
       "9     181\n",
       "4     180\n",
       "Name: Fold, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use Assign_Train_Test to assign cross-validation folds\n",
    "\n",
    "train['Fold'] = train.apply(Assign_Train_Test,axis = 1)\n",
    "\n",
    "train['Fold'].value_counts()   #All folds are approximately equal size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Param Combo Number 1 Avg Precision = 0.643543223991\n",
      "Fold 1 Param Combo Number 2 Avg Precision = 0.642420244952\n",
      "Fold 1 Param Combo Number 3 Avg Precision = 0.644857154379\n",
      "Fold 1 Param Combo Number 4 Avg Precision = 0.634053948009\n",
      "Fold 1 Param Combo Number 5 Avg Precision = 0.629681765094\n",
      "Fold 1 Param Combo Number 6 Avg Precision = 0.651833243856\n",
      "Fold 1 Param Combo Number 7 Avg Precision = 0.648508737276\n",
      "Fold 1 Param Combo Number 8 Avg Precision = 0.65166628614\n",
      "Fold 1 Param Combo Number 9 Avg Precision = 0.641828704983\n",
      "Fold 1 Param Combo Number 10 Avg Precision = 0.641303621066\n",
      "Fold 1 Param Combo Number 11 Avg Precision = 0.667009456708\n",
      "Fold 1 Param Combo Number 12 Avg Precision = 0.640071964644\n",
      "Fold 1 Param Combo Number 13 Avg Precision = 0.640255844922\n",
      "Fold 1 Param Combo Number 14 Avg Precision = 0.630191771339\n",
      "Fold 1 Param Combo Number 15 Avg Precision = 0.630827012836\n",
      "Fold 1 Param Combo Number 16 Avg Precision = 0.664978353385\n",
      "Fold 1 Param Combo Number 17 Avg Precision = 0.646488580748\n",
      "Fold 1 Param Combo Number 18 Avg Precision = 0.633554583769\n",
      "Fold 1 Param Combo Number 19 Avg Precision = 0.637730333403\n",
      "Fold 1 Param Combo Number 20 Avg Precision = 0.638849229203\n",
      "Best Params for Outer Fold 1 | Number of Trees = 200 | Max Depth = 2\n",
      "Fold 1 Error Metric: 0.7\n",
      "Fold 2 Param Combo Number 1 Avg Precision = 0.653789528944\n",
      "Fold 2 Param Combo Number 2 Avg Precision = 0.663507931166\n",
      "Fold 2 Param Combo Number 3 Avg Precision = 0.64619949664\n",
      "Fold 2 Param Combo Number 4 Avg Precision = 0.649427360211\n",
      "Fold 2 Param Combo Number 5 Avg Precision = 0.655632449146\n",
      "Fold 2 Param Combo Number 6 Avg Precision = 0.676531667968\n",
      "Fold 2 Param Combo Number 7 Avg Precision = 0.649672827479\n",
      "Fold 2 Param Combo Number 8 Avg Precision = 0.657842637691\n",
      "Fold 2 Param Combo Number 9 Avg Precision = 0.651177287017\n",
      "Fold 2 Param Combo Number 10 Avg Precision = 0.642300995768\n",
      "Fold 2 Param Combo Number 11 Avg Precision = 0.67349496045\n",
      "Fold 2 Param Combo Number 12 Avg Precision = 0.653467525377\n",
      "Fold 2 Param Combo Number 13 Avg Precision = 0.647295151375\n",
      "Fold 2 Param Combo Number 14 Avg Precision = 0.653436239849\n",
      "Fold 2 Param Combo Number 15 Avg Precision = 0.645446954275\n",
      "Fold 2 Param Combo Number 16 Avg Precision = 0.677650274561\n",
      "Fold 2 Param Combo Number 17 Avg Precision = 0.656354257695\n",
      "Fold 2 Param Combo Number 18 Avg Precision = 0.65914956809\n",
      "Fold 2 Param Combo Number 19 Avg Precision = 0.651771334342\n",
      "Fold 2 Param Combo Number 20 Avg Precision = 0.64262274228\n",
      "Best Params for Outer Fold 2 | Number of Trees = 300 | Max Depth = 2\n",
      "Fold 2 Error Metric: 0.69\n",
      "Fold 3 Param Combo Number 1 Avg Precision = 0.644201752928\n",
      "Fold 3 Param Combo Number 2 Avg Precision = 0.643335280231\n",
      "Fold 3 Param Combo Number 3 Avg Precision = 0.643658512097\n",
      "Fold 3 Param Combo Number 4 Avg Precision = 0.633366964288\n",
      "Fold 3 Param Combo Number 5 Avg Precision = 0.61963395663\n",
      "Fold 3 Param Combo Number 6 Avg Precision = 0.659899629071\n",
      "Fold 3 Param Combo Number 7 Avg Precision = 0.643529858015\n",
      "Fold 3 Param Combo Number 8 Avg Precision = 0.63089980991\n",
      "Fold 3 Param Combo Number 9 Avg Precision = 0.630329336843\n",
      "Fold 3 Param Combo Number 10 Avg Precision = 0.631298522009\n",
      "Fold 3 Param Combo Number 11 Avg Precision = 0.648895218493\n",
      "Fold 3 Param Combo Number 12 Avg Precision = 0.637365069496\n",
      "Fold 3 Param Combo Number 13 Avg Precision = 0.639911949063\n",
      "Fold 3 Param Combo Number 14 Avg Precision = 0.63988836172\n",
      "Fold 3 Param Combo Number 15 Avg Precision = 0.633590675799\n",
      "Fold 3 Param Combo Number 16 Avg Precision = 0.654661570685\n",
      "Fold 3 Param Combo Number 17 Avg Precision = 0.632247553035\n",
      "Fold 3 Param Combo Number 18 Avg Precision = 0.639980925845\n",
      "Fold 3 Param Combo Number 19 Avg Precision = 0.633896632934\n",
      "Fold 3 Param Combo Number 20 Avg Precision = 0.633213377899\n",
      "Best Params for Outer Fold 3 | Number of Trees = 100 | Max Depth = 2\n",
      "Fold 3 Error Metric: 0.65\n",
      "Fold 4 Param Combo Number 1 Avg Precision = 0.657622141623\n",
      "Fold 4 Param Combo Number 2 Avg Precision = 0.65000699525\n",
      "Fold 4 Param Combo Number 3 Avg Precision = 0.638902607533\n",
      "Fold 4 Param Combo Number 4 Avg Precision = 0.642155798596\n",
      "Fold 4 Param Combo Number 5 Avg Precision = 0.642273408332\n",
      "Fold 4 Param Combo Number 6 Avg Precision = 0.672762423985\n",
      "Fold 4 Param Combo Number 7 Avg Precision = 0.664766349305\n",
      "Fold 4 Param Combo Number 8 Avg Precision = 0.644947420344\n",
      "Fold 4 Param Combo Number 9 Avg Precision = 0.638276477703\n",
      "Fold 4 Param Combo Number 10 Avg Precision = 0.640404885341\n",
      "Fold 4 Param Combo Number 11 Avg Precision = 0.668265713322\n",
      "Fold 4 Param Combo Number 12 Avg Precision = 0.655056322702\n",
      "Fold 4 Param Combo Number 13 Avg Precision = 0.651944073887\n",
      "Fold 4 Param Combo Number 14 Avg Precision = 0.640096686835\n",
      "Fold 4 Param Combo Number 15 Avg Precision = 0.634635878184\n",
      "Fold 4 Param Combo Number 16 Avg Precision = 0.670551254606\n",
      "Fold 4 Param Combo Number 17 Avg Precision = 0.650662325973\n",
      "Fold 4 Param Combo Number 18 Avg Precision = 0.654139194408\n",
      "Fold 4 Param Combo Number 19 Avg Precision = 0.638504532763\n",
      "Fold 4 Param Combo Number 20 Avg Precision = 0.639495182432\n",
      "Best Params for Outer Fold 4 | Number of Trees = 100 | Max Depth = 2\n",
      "Fold 4 Error Metric: 0.67\n",
      "Fold 5 Param Combo Number 1 Avg Precision = 0.663407738392\n",
      "Fold 5 Param Combo Number 2 Avg Precision = 0.641828961315\n",
      "Fold 5 Param Combo Number 3 Avg Precision = 0.634798737627\n",
      "Fold 5 Param Combo Number 4 Avg Precision = 0.638329793318\n",
      "Fold 5 Param Combo Number 5 Avg Precision = 0.634545282261\n",
      "Fold 5 Param Combo Number 6 Avg Precision = 0.672841020503\n",
      "Fold 5 Param Combo Number 7 Avg Precision = 0.656870578846\n",
      "Fold 5 Param Combo Number 8 Avg Precision = 0.646478355303\n",
      "Fold 5 Param Combo Number 9 Avg Precision = 0.632228918186\n",
      "Fold 5 Param Combo Number 10 Avg Precision = 0.634906328512\n",
      "Fold 5 Param Combo Number 11 Avg Precision = 0.666126806975\n",
      "Fold 5 Param Combo Number 12 Avg Precision = 0.651542771915\n",
      "Fold 5 Param Combo Number 13 Avg Precision = 0.642985796163\n",
      "Fold 5 Param Combo Number 14 Avg Precision = 0.634106301359\n",
      "Fold 5 Param Combo Number 15 Avg Precision = 0.634609971288\n",
      "Fold 5 Param Combo Number 16 Avg Precision = 0.667393718043\n",
      "Fold 5 Param Combo Number 17 Avg Precision = 0.648654714506\n",
      "Fold 5 Param Combo Number 18 Avg Precision = 0.642864368983\n",
      "Fold 5 Param Combo Number 19 Avg Precision = 0.645194330971\n",
      "Fold 5 Param Combo Number 20 Avg Precision = 0.629386712677\n",
      "Best Params for Outer Fold 5 | Number of Trees = 100 | Max Depth = 2\n",
      "Fold 5 Error Metric: 0.68\n",
      "Fold 6 Param Combo Number 1 Avg Precision = 0.681245610823\n",
      "Fold 6 Param Combo Number 2 Avg Precision = 0.668508059397\n",
      "Fold 6 Param Combo Number 3 Avg Precision = 0.658993896076\n",
      "Fold 6 Param Combo Number 4 Avg Precision = 0.655772703577\n",
      "Fold 6 Param Combo Number 5 Avg Precision = 0.649822307495\n",
      "Fold 6 Param Combo Number 6 Avg Precision = 0.674754628146\n",
      "Fold 6 Param Combo Number 7 Avg Precision = 0.660230211556\n",
      "Fold 6 Param Combo Number 8 Avg Precision = 0.646483471318\n",
      "Fold 6 Param Combo Number 9 Avg Precision = 0.640324261366\n",
      "Fold 6 Param Combo Number 10 Avg Precision = 0.648347653842\n",
      "Fold 6 Param Combo Number 11 Avg Precision = 0.681094881436\n",
      "Fold 6 Param Combo Number 12 Avg Precision = 0.662321216745\n",
      "Fold 6 Param Combo Number 13 Avg Precision = 0.649611738773\n",
      "Fold 6 Param Combo Number 14 Avg Precision = 0.647471975108\n",
      "Fold 6 Param Combo Number 15 Avg Precision = 0.647214869859\n",
      "Fold 6 Param Combo Number 16 Avg Precision = 0.679153925599\n",
      "Fold 6 Param Combo Number 17 Avg Precision = 0.654670125282\n",
      "Fold 6 Param Combo Number 18 Avg Precision = 0.650268548648\n",
      "Fold 6 Param Combo Number 19 Avg Precision = 0.652223526082\n",
      "Fold 6 Param Combo Number 20 Avg Precision = 0.651997724085\n",
      "Best Params for Outer Fold 6 | Number of Trees = 50 | Max Depth = 2\n",
      "Fold 6 Error Metric: 0.68\n",
      "Fold 7 Param Combo Number 1 Avg Precision = 0.663635432595\n",
      "Fold 7 Param Combo Number 2 Avg Precision = 0.647710833972\n",
      "Fold 7 Param Combo Number 3 Avg Precision = 0.64727573547\n",
      "Fold 7 Param Combo Number 4 Avg Precision = 0.654349082699\n",
      "Fold 7 Param Combo Number 5 Avg Precision = 0.638833255891\n",
      "Fold 7 Param Combo Number 6 Avg Precision = 0.674850455228\n",
      "Fold 7 Param Combo Number 7 Avg Precision = 0.638183508325\n",
      "Fold 7 Param Combo Number 8 Avg Precision = 0.647107831489\n",
      "Fold 7 Param Combo Number 9 Avg Precision = 0.642647021029\n",
      "Fold 7 Param Combo Number 10 Avg Precision = 0.643087830205\n",
      "Fold 7 Param Combo Number 11 Avg Precision = 0.664722988225\n",
      "Fold 7 Param Combo Number 12 Avg Precision = 0.647756008504\n",
      "Fold 7 Param Combo Number 13 Avg Precision = 0.640235516021\n",
      "Fold 7 Param Combo Number 14 Avg Precision = 0.643820582102\n",
      "Fold 7 Param Combo Number 15 Avg Precision = 0.629387070076\n",
      "Fold 7 Param Combo Number 16 Avg Precision = 0.663857727755\n",
      "Fold 7 Param Combo Number 17 Avg Precision = 0.654998780037\n",
      "Fold 7 Param Combo Number 18 Avg Precision = 0.642610068079\n",
      "Fold 7 Param Combo Number 19 Avg Precision = 0.642359660563\n",
      "Fold 7 Param Combo Number 20 Avg Precision = 0.636133186714\n",
      "Best Params for Outer Fold 7 | Number of Trees = 100 | Max Depth = 2\n",
      "Fold 7 Error Metric: 0.7\n",
      "Fold 8 Param Combo Number 1 Avg Precision = 0.648079771809\n",
      "Fold 8 Param Combo Number 2 Avg Precision = 0.639494633492\n",
      "Fold 8 Param Combo Number 3 Avg Precision = 0.632136511682\n",
      "Fold 8 Param Combo Number 4 Avg Precision = 0.62335948857\n",
      "Fold 8 Param Combo Number 5 Avg Precision = 0.616240974704\n",
      "Fold 8 Param Combo Number 6 Avg Precision = 0.647436689186\n",
      "Fold 8 Param Combo Number 7 Avg Precision = 0.641328663095\n",
      "Fold 8 Param Combo Number 8 Avg Precision = 0.639302350222\n",
      "Fold 8 Param Combo Number 9 Avg Precision = 0.628362954076\n",
      "Fold 8 Param Combo Number 10 Avg Precision = 0.621100226881\n",
      "Fold 8 Param Combo Number 11 Avg Precision = 0.65651504156\n",
      "Fold 8 Param Combo Number 12 Avg Precision = 0.636188282932\n",
      "Fold 8 Param Combo Number 13 Avg Precision = 0.634837355883\n",
      "Fold 8 Param Combo Number 14 Avg Precision = 0.633210220573\n",
      "Fold 8 Param Combo Number 15 Avg Precision = 0.615502528171\n",
      "Fold 8 Param Combo Number 16 Avg Precision = 0.646729053072\n",
      "Fold 8 Param Combo Number 17 Avg Precision = 0.636345335298\n",
      "Fold 8 Param Combo Number 18 Avg Precision = 0.633149052889\n",
      "Fold 8 Param Combo Number 19 Avg Precision = 0.631508929951\n",
      "Fold 8 Param Combo Number 20 Avg Precision = 0.628282545346\n",
      "Best Params for Outer Fold 8 | Number of Trees = 200 | Max Depth = 2\n",
      "Fold 8 Error Metric: 0.76\n",
      "Fold 9 Param Combo Number 1 Avg Precision = 0.670952580835\n",
      "Fold 9 Param Combo Number 2 Avg Precision = 0.654108372993\n",
      "Fold 9 Param Combo Number 3 Avg Precision = 0.659079332339\n",
      "Fold 9 Param Combo Number 4 Avg Precision = 0.655866241481\n",
      "Fold 9 Param Combo Number 5 Avg Precision = 0.649284966334\n",
      "Fold 9 Param Combo Number 6 Avg Precision = 0.683233206193\n",
      "Fold 9 Param Combo Number 7 Avg Precision = 0.66388394812\n",
      "Fold 9 Param Combo Number 8 Avg Precision = 0.660681254551\n",
      "Fold 9 Param Combo Number 9 Avg Precision = 0.649096953715\n",
      "Fold 9 Param Combo Number 10 Avg Precision = 0.646513430429\n",
      "Fold 9 Param Combo Number 11 Avg Precision = 0.687215097626\n",
      "Fold 9 Param Combo Number 12 Avg Precision = 0.669504903201\n",
      "Fold 9 Param Combo Number 13 Avg Precision = 0.660356530158\n",
      "Fold 9 Param Combo Number 14 Avg Precision = 0.6557606662\n",
      "Fold 9 Param Combo Number 15 Avg Precision = 0.651882070374\n",
      "Fold 9 Param Combo Number 16 Avg Precision = 0.671164185981\n",
      "Fold 9 Param Combo Number 17 Avg Precision = 0.66059582049\n",
      "Fold 9 Param Combo Number 18 Avg Precision = 0.655688316226\n",
      "Fold 9 Param Combo Number 19 Avg Precision = 0.654481404326\n",
      "Fold 9 Param Combo Number 20 Avg Precision = 0.64381772975\n",
      "Best Params for Outer Fold 9 | Number of Trees = 200 | Max Depth = 2\n",
      "Fold 9 Error Metric: 0.67\n",
      "Fold 10 Param Combo Number 1 Avg Precision = 0.665010198539\n",
      "Fold 10 Param Combo Number 2 Avg Precision = 0.675658260297\n",
      "Fold 10 Param Combo Number 3 Avg Precision = 0.657945492625\n",
      "Fold 10 Param Combo Number 4 Avg Precision = 0.655578625649\n",
      "Fold 10 Param Combo Number 5 Avg Precision = 0.646470421719\n",
      "Fold 10 Param Combo Number 6 Avg Precision = 0.68567142613\n",
      "Fold 10 Param Combo Number 7 Avg Precision = 0.677681975176\n",
      "Fold 10 Param Combo Number 8 Avg Precision = 0.655405190039\n",
      "Fold 10 Param Combo Number 9 Avg Precision = 0.648868326126\n",
      "Fold 10 Param Combo Number 10 Avg Precision = 0.651692033645\n",
      "Fold 10 Param Combo Number 11 Avg Precision = 0.679057937355\n",
      "Fold 10 Param Combo Number 12 Avg Precision = 0.671385170822\n",
      "Fold 10 Param Combo Number 13 Avg Precision = 0.667756140474\n",
      "Fold 10 Param Combo Number 14 Avg Precision = 0.650517837671\n",
      "Fold 10 Param Combo Number 15 Avg Precision = 0.649967289471\n",
      "Fold 10 Param Combo Number 16 Avg Precision = 0.679734332527\n",
      "Fold 10 Param Combo Number 17 Avg Precision = 0.669776852591\n",
      "Fold 10 Param Combo Number 18 Avg Precision = 0.662360311113\n",
      "Fold 10 Param Combo Number 19 Avg Precision = 0.653011899577\n",
      "Fold 10 Param Combo Number 20 Avg Precision = 0.65212654176\n",
      "Best Params for Outer Fold 10 | Number of Trees = 100 | Max Depth = 2\n",
      "Fold 10 Error Metric: 0.55\n",
      "****************************************************\n",
      "Average Error Metric= 0.67414\n",
      "Best Parameters:  Number of Trees = 300 Max Depth = 2\n"
     ]
    }
   ],
   "source": [
    "## Set up cross-validation loop\n",
    "\n",
    "cv_accuracy = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "\n",
    "#kernel_choice = ['rbf','poly','sigmoid']\n",
    "n_trees = [50,100,200,300]\n",
    "depths = [2,3,4,5,6]\n",
    "\n",
    "outer_param_scores = {}\n",
    "outer_error_metric = []\n",
    "\n",
    "summary_error = pd.DataFrame()\n",
    "\n",
    "\n",
    "for fold in range(1,numFolds+1):\n",
    "    \n",
    "    # Outer Cross-Validation\n",
    "    \n",
    "    cv_train = train[train['Fold'] != fold]\n",
    "    cv_test = train[train['Fold'] == fold]\n",
    "    \n",
    "    del cv_train['Fold']\n",
    "    del cv_test['Fold']\n",
    "    \n",
    "    y_train = cv_train['Result_Target'].copy()\n",
    "    x_train = cv_train.copy()\n",
    "    del x_train['Result_Target']\n",
    "\n",
    "    \n",
    "    y_test = cv_test['Result_Target'].copy()\n",
    "    del cv_test['Result_Target']\n",
    "    x_test = cv_test.copy()\n",
    "    \n",
    "    # Set up inner cross-validation\n",
    "    \n",
    "    inner_train = cv_train.copy()\n",
    "    del cv_train['Result_Target']\n",
    "    \n",
    "    inner_train['Inner_Fold'] = inner_train.apply(Assign_Train_Test, axis = 1)\n",
    "    \n",
    "    best_hyper_params = {}\n",
    "    #se = {}\n",
    "    \n",
    "    paramComboDict = {}\n",
    "    error_dict = {}\n",
    "    outerfold = []\n",
    "    inner_average = []\n",
    "    paramnum = []\n",
    "    paramComboNum = 0\n",
    "    \n",
    "    # Iterate thru hyperparameter search\n",
    "    for k in n_trees:\n",
    "        #if k == 'poly':\n",
    "        #    gamma_list = [2,3,4]\n",
    "        #else:\n",
    "        #    gamma_list = [.01,.1,.2,.5,1]\n",
    "        for g in depths:\n",
    "            \n",
    "            paramComboNum += 1\n",
    "            paramComboDict[paramComboNum] ={'Depth': g,\n",
    "                                            'N_Trees': k}\n",
    "            if verbose:\n",
    "                print paramComboNum\n",
    "                \n",
    "            error_metric = []\n",
    "    \n",
    "            for inner_fold in range(1,numFolds+1):\n",
    "            \n",
    "                #print 'Inner Fold: ' + str(inner_fold)\n",
    "        \n",
    "                inner_cv_train = inner_train[inner_train['Inner_Fold']!= inner_fold]\n",
    "                inner_cv_test = inner_train[inner_train['Inner_Fold']== inner_fold]\n",
    "        \n",
    "                del inner_cv_train['Inner_Fold']\n",
    "                del inner_cv_test['Inner_Fold']\n",
    "        \n",
    "                y_inner_train = inner_cv_train['Result_Target']\n",
    "                del inner_cv_train['Result_Target']\n",
    "                x_inner_train = inner_cv_train.copy()\n",
    "    \n",
    "                y_inner_test = inner_cv_test['Result_Target']\n",
    "                del inner_cv_test['Result_Target']\n",
    "                x_inner_test = inner_cv_test.copy()\n",
    "                \n",
    "                clf = RandomForestClassifier(n_estimators = k, max_depth = g)\n",
    "                #if k == 'poly':\n",
    "                #    clf = SVC(kernel = 'poly',degree = g, class_weight = 'balanced')\n",
    "                #else:\n",
    "                #    clf = SVC(kernel = k,gamma = g)\n",
    "                \n",
    "                preds = FitPredict(x_inner_train,y_inner_train,x_inner_test,clf)\n",
    "    \n",
    "                cem, precision,recall = ComputeErrorMetric(y_inner_test,preds)  # Calculate combined error metric\n",
    "        \n",
    "                error_metric.append(precision)\n",
    "              \n",
    "                #if cem > 0:\n",
    "                #print 'Precision = ' + str(precision) + ' | ' + 'Recall = ' + str(recall)\n",
    "                    \n",
    "            \n",
    "            avg_error_metric = np.mean(error_metric)\n",
    "            em_std_err = sem(error_metric)\n",
    "            \n",
    "            print 'Fold ' + str(fold) + ' Param Combo Number ' + str(paramComboNum) + ' Avg Precision = ' + str((avg_error_metric - em_std_err))\n",
    "            outerfold.append(fold)\n",
    "            inner_average.append(avg_error_metric - em_std_err)\n",
    "            paramnum.append(paramComboNum)\n",
    "    \n",
    "    \n",
    "    if 'outerfold' in summary_error.columns and'inner_average' in summary_error.columns and 'paramnum' in summary_error.columns:\n",
    "        temp_df = pd.DataFrame({'outerfold':outerfold,'inner_average':inner_average,'paramnum':paramnum})\n",
    "        summary_error = pd.concat([summary_error, temp_df])    \n",
    "    else:   \n",
    "        summary_error['outerfold'] = outerfold\n",
    "        summary_error['inner_average'] = inner_average\n",
    "        summary_error['paramnum'] = paramnum\n",
    "    \n",
    "    sub = summary_error[summary_error['outerfold']==fold]\n",
    "        \n",
    "    best_params = paramComboDict[sub['paramnum'][sub['inner_average'].idxmax()]]\n",
    "    \n",
    "    k = best_params['N_Trees']\n",
    "    g = best_params['Depth']\n",
    "    \n",
    "    print 'Best Params for Outer Fold ' + str(fold) + ' | ' + 'Number of Trees = ' + str(k) + ' | ' + 'Max Depth = ' + str(g)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators = k, max_depth = g)  \n",
    "    \n",
    "    #if k == 'poly':\n",
    "    #    clf = SVC(kernel = k, degree = float(g))\n",
    "    #else:\n",
    "    #    clf = SVC(kernel = k, gamma = float(g))\n",
    "    \n",
    "    preds = FitPredict(x_train,y_train,x_test,clf)\n",
    "    \n",
    "    cem, precision,recall = ComputeErrorMetric(y_test,preds)\n",
    "    \n",
    "    outer_error_metric.append(precision)\n",
    "    \n",
    "    print 'Fold ' + str(fold) + ' Error Metric: ' + str(round(precision,2))\n",
    "    \n",
    "    outer_param_scores[sub['paramnum'][sub['inner_average'].idxmax()]] = precision\n",
    "\n",
    "for key in outer_param_scores.keys():\n",
    "    if outer_param_scores[key] == max(outer_param_scores.values()):\n",
    "        best_combo = key\n",
    "        \n",
    "best_params = paramComboDict[best_combo]\n",
    "\n",
    "best_k = best_params['N_Trees']\n",
    "best_gamma = best_params['Depth']\n",
    "\n",
    "avg_error_metric = np.mean(outer_error_metric)   \n",
    "    \n",
    "    \n",
    "print '****************************************************'\n",
    "print 'Average Error Metric= ' + str(avg_error_metric)\n",
    "print 'Best Parameters: ' + ' Number of Trees = ' + str(best_k) + ' Max Depth = ' + str(best_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout Set Error Metric = 0.65\n",
      "Precision = 0.6508\n"
     ]
    }
   ],
   "source": [
    "## Prepare for test\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "x_train = train.copy()\n",
    "x_test = holdout.copy()\n",
    "\n",
    "y_train = x_train['Result_Target']\n",
    "del x_train['Result_Target']\n",
    "del x_train['Fold']\n",
    "\n",
    "y_test = x_test['Result_Target']\n",
    "del x_test['Result_Target']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 200, max_depth = 2, random_state = 1988)\n",
    "\n",
    "preds = FitPredict(x_train,y_train,x_test,clf)\n",
    "cem, precision, recall = ComputeErrorMetric(y_test,preds)\n",
    "\n",
    "print 'Holdout Set Error Metric = ' + str(round(precision,2))\n",
    "print 'Precision = ' + str(precision)\n",
    "#print 'Recall = ' + str(recall)\n",
    "\n",
    "## Metric to beat SVM = 0.5301\n",
    "## Metric after optimizing gamma / decision_function SVM = .5465\n",
    "## Metric Random Forest n_estimators = 200, max_depth = 2 = .65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>116</td>\n",
       "      <td>22</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>67</td>\n",
       "      <td>41</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>183</td>\n",
       "      <td>63</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0  All\n",
       "Actual                  \n",
       "0.0        116   22  138\n",
       "1.0         67   41  108\n",
       "All        183   63  246"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion = pd.crosstab(y_test,preds, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, build model based off of entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = data.copy()\n",
    "\n",
    "y_train = x_train['Result_Target'].copy()\n",
    "del x_train['Result_Target']\n",
    "\n",
    "clf = SVC(kernel = 'poly', degree = 2)\n",
    "\n",
    "fit_clf = clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/mtetkosk/Google Drive/Data Science Projects/models/%s_SVC_Model_Champion.pkl'%(date), 'wb') as f:\n",
    "    pickle.dump(fit_clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Results_Df = pd.DataFrame({'Date': date, 'Holdout Precision': precision, 'Kernel': best_k, 'Degree': best_gamma}, index=[0])\n",
    "\n",
    "Results_Df.to_csv('/Users/mtetkosk/Google Drive/Data Science Projects/models/%s_SVM_Model_Champion.csv'%(date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betting Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_home_odds = x_test['Average_Home_Odds'].copy()\n",
    "test_away_odds = x_test['Average_Away_Odds'].copy()\n",
    "draw_odds = x_test['Average_Draw_Odds'].copy()\n",
    "bet_preds = preds.copy()\n",
    "actual_results = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Away_Odds</th>\n",
       "      <th>Draw_Odds</th>\n",
       "      <th>Home_Odds</th>\n",
       "      <th>Model_Preds</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.50</td>\n",
       "      <td>5.92</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.75</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.15</td>\n",
       "      <td>3.51</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.83</td>\n",
       "      <td>6.92</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.17</td>\n",
       "      <td>6.92</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.62</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12.83</td>\n",
       "      <td>5.50</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5.77</td>\n",
       "      <td>3.82</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7.67</td>\n",
       "      <td>4.22</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3.88</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8.08</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>14.67</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>9.50</td>\n",
       "      <td>5.29</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>7.08</td>\n",
       "      <td>3.96</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>7.54</td>\n",
       "      <td>4.23</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>12.08</td>\n",
       "      <td>5.67</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>8.26</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>13.92</td>\n",
       "      <td>5.71</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>7.28</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>10.42</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>6.62</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>10.22</td>\n",
       "      <td>4.81</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4.79</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>8.38</td>\n",
       "      <td>4.68</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>11.92</td>\n",
       "      <td>5.46</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Away_Odds  Draw_Odds  Home_Odds  Model_Preds  Result\n",
       "3        12.50       5.92       1.20          1.0     1.0\n",
       "4         8.75       4.45       1.39          1.0     1.0\n",
       "8         4.15       3.51       1.84          1.0     1.0\n",
       "11       16.83       6.92       1.14          1.0     1.0\n",
       "12       15.17       6.92       1.15          1.0     1.0\n",
       "13        4.62       3.40       1.77          1.0     1.0\n",
       "18       12.83       5.50       1.24          1.0     1.0\n",
       "30        5.77       3.82       1.57          1.0     1.0\n",
       "39        7.67       4.22       1.43          1.0     0.0\n",
       "40        3.88       3.23       1.98          1.0     0.0\n",
       "41        8.08       4.12       1.43          1.0     1.0\n",
       "42       14.67       5.70       1.20          1.0     1.0\n",
       "47        9.50       5.29       1.30          1.0     0.0\n",
       "58        7.08       3.96       1.48          1.0     1.0\n",
       "62        7.54       4.23       1.44          1.0     1.0\n",
       "70       12.08       5.67       1.24          1.0     0.0\n",
       "79        8.26       4.67       1.37          1.0     1.0\n",
       "80       13.92       5.71       1.22          1.0     1.0\n",
       "87        7.28       4.10       1.46          1.0     1.0\n",
       "92       10.42       5.33       1.29          1.0     1.0\n",
       "93        6.62       3.94       1.52          1.0     0.0\n",
       "97       10.22       4.81       1.32          1.0     1.0\n",
       "98        4.79       3.52       1.74          1.0     1.0\n",
       "99        8.38       4.68       1.37          1.0     1.0\n",
       "100      11.92       5.46       1.26          1.0     1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Betting_df = pd.DataFrame({'Home_Odds':test_home_odds,'Away_Odds':test_away_odds,'Draw_Odds': draw_odds,'Model_Preds':bet_preds,'Result': y_test.copy()})\n",
    "Betting_df = Betting_df.reset_index(drop=True)\n",
    "Betting_df[Betting_df['Model_Preds']==1][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Betting Analysis Function\n",
    "\n",
    "def BettingAnalysis(df,purse,bet):\n",
    "    initial_purse = purse\n",
    "    purse_track = []\n",
    "    for match in range(len(df)):\n",
    "        pred = df['Model_Preds'][match]\n",
    "        result = df['Result'][match]\n",
    "        home_odds = df['Home_Odds'][match]\n",
    "        away_odds = df['Away_Odds'][match]\n",
    "        draw_odds = df['Draw_Odds'][match]\n",
    "        if pred == 0:\n",
    "            purse_track.append(purse)\n",
    "            continue\n",
    "        if pred == 1 and pred == result:\n",
    "            #if pred == 1:\n",
    "            #    win = round(bet*home_odds,2)-bet\n",
    "            #    purse += win\n",
    "            #if pred == -1: #simulate no bet\n",
    "            #    win = round(bet*away_odds,2)-bet\n",
    "            #    purse += win\n",
    "            #purse_track.append(purse)\n",
    "            if pred == 1:\n",
    "                win = round(bet*home_odds,2)-bet\n",
    "                assert win > 0\n",
    "                purse += win\n",
    "        else:\n",
    "            purse = purse - bet\n",
    "            purse_track.append(purse)\n",
    "    \n",
    "    if purse > initial_purse:\n",
    "        profit = purse-initial_purse\n",
    "        #return 'You profited ' +str(round(profit,2)) +'!'\n",
    "        return purse_track\n",
    "    if purse == initial_purse:\n",
    "        #return 'You broke even!'\n",
    "        return purse_track\n",
    "    if purse < initial_purse:\n",
    "        loss = purse-initial_purse\n",
    "        #return 'You lost ' + str(abs(round(loss,2))) + 'now you\\'re broke!'\n",
    "        return purse_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "purse_track = BettingAnalysis(Betting_df,100,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1170a7950>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGHCAYAAABrpPKuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116116ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(purse_track)\n",
    "plt.xlabel('Match Number')\n",
    "plt.ylabel('Betting Balance $')\n",
    "plt.title('Betting Algorithm Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
